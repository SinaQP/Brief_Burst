{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTrT64JB8MeVAHhW8X5oEk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SinaQP/Brief_Burst/blob/main/Brief_Burst.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dgMKvLON5Td",
        "outputId": "3d64aa64-d0d7-4fe2-f38d-45d32588498e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/473.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m368.6/473.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.2/473.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m2.3/2.5 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install openai langchain langchain-community langchain-openai faiss-cpu --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx2txt python-docx --upgrade --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERcIivY9Q5OO",
        "outputId": "7257ea5e-a256-4312-fbec-e075336ab0fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/244.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/244.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "class AvalaiClient:\n",
        "    def __init__(self, api_key=\"\", base_url=\"\", model_name=\"gpt-4o-mini\"):\n",
        "        self.api_key, self.base_url = self._set_api_config(api_key, base_url)\n",
        "        self.model_name = model_name\n",
        "        self.client = openai.OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
        "\n",
        "    def get_chat_model(self):\n",
        "        return ChatOpenAI(model_name=self.model_name, openai_api_key=self.api_key, openai_api_base=self.base_url)\n",
        "\n",
        "    def get_embeddings(self):\n",
        "        return OpenAIEmbeddings(openai_api_key=self.api_key, openai_api_base=self.base_url)\n",
        "\n",
        "    def _set_api_config(self, api_key, base_url):\n",
        "        default_api_key = \"\"\n",
        "        default_base_url = \"https://api.avalai.ir/v1\"\n",
        "        return api_key or default_api_key, base_url or default_base_url\n",
        "\n"
      ],
      "metadata": {
        "id": "rr1eluOdOji8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avalai_client = AvalaiClient()\n",
        "llm = avalai_client.get_chat_model()"
      ],
      "metadata": {
        "id": "8d0NxsFKOkCt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import Docx2txtLoader\n",
        "\n",
        "loader = Docx2txtLoader('./The Evolution of Job Search Technology.docx')\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5IHPOuNO4et",
        "outputId": "a79d123d-ff7f-42c2-c650-b092492112b9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': './The Evolution of Job Search Technology.docx'}, page_content='The Evolution of Job Search Technology\\n\\n\\n\\nIntroduction: The Dawn of Employment Exploration\\n\\n\\n\\n\\nThe quest for meaningful work has been a cornerstone of human existence, evolving alongside societal and technological advancements. In the earliest days, job searches were informal—word of mouth in tight-knit communities or apprenticeships arranged through familial ties. However, as populations grew and industries emerged, the need for structured job-finding mechanisms became evident. Fast forward to the 21st century, and the landscape of job searching has transformed dramatically, driven by technological innovation. This document explores the evolution of job search technology, from rudimentary postings to sophisticated artificial intelligence systems, and speculates on the future of employment discovery.\\n\\n\\n\\nThe Pre-Digital Era: Newspapers and Noticeboards\\n\\n\\n\\n\\nBefore the internet, job seekers relied heavily on physical mediums. In the 19th and early 20th centuries, newspapers were the primary vehicle for job advertisements. Employers would place small, text-heavy listings in classified sections, often requiring candidates to respond via mail or in person. These ads were concise, limited by space and cost, and offered little insight into the role beyond basic requirements. Alongside newspapers, community noticeboards—in churches, town halls, or local shops—served as hubs for opportunities, particularly in rural areas. While effective for their time, these methods were slow, geographically constrained, and favored those with access to print media or local networks.\\n\\n\\n\\n\\nThe process was labor-intensive for both parties. Job seekers had to scour pages daily, while employers sifted through stacks of handwritten applications. Success depended on timing, persistence, and often luck. Yet, this era laid the groundwork for a cultural shift: the idea that work could be sought systematically rather than stumbled upon.\\n\\n\\n\\nThe Digital Revolution: Online Job Boards\\n\\n\\n\\n\\nThe arrival of the internet in the 1990s revolutionized job searching. Online job boards like Monster.com (launched in 1994) and CareerBuilder (1995) digitized the classifieds model, offering searchable databases of opportunities. Suddenly, job seekers could filter listings by location, industry, or salary, and employers could reach a global audience instantly. Resumes moved from paper to email, and the pace of hiring accelerated.\\n\\n\\n\\n\\nThese platforms introduced new dynamics. Keywords became king—applicants tailored resumes to match search algorithms, while employers competed to make postings stand out. The downside? Oversaturation. By the early 2000s, job boards were flooded with listings, many outdated or duplicated, leading to “application black holes” where candidates rarely heard back. Despite this, the shift to digital marked a turning point, democratizing access and setting the stage for more interactive tools.\\n\\n\\n\\nThe Social Media Era: Networking Goes Virtual\\n\\n\\n\\n\\nAs social media platforms emerged, they reshaped job searching yet again. LinkedIn, launched in 2003, blended professional networking with recruitment. Unlike job boards, LinkedIn emphasized relationships—users built profiles showcasing skills, endorsements, and connections, while recruiters scouted talent proactively. By 2010, companies were posting jobs directly on the platform, and features like “Easy Apply” streamlined applications.\\n\\n\\n\\n\\nTwitter and Facebook also entered the fray. Job seekers followed industry leaders for insider tips, while employers teased openings through hashtags like #JobOpening. This era blurred the lines between personal branding and job hunting, encouraging individuals to curate online personas. However, it also amplified competition—standing out required more than a resume; it demanded a narrative.\\n\\n\\n\\nThe Rise of Algorithms and AI\\n\\n\\n\\n\\nThe 2010s ushered in a new frontier: artificial intelligence. Companies like Indeed and Glassdoor refined search algorithms, aggregating listings from across the web and ranking them by relevance. Machine learning began predicting candidate-job matches based on patterns in applications, skills, and outcomes. For employers, applicant tracking systems (ATS) filtered resumes with ruthless efficiency, prioritizing those with the right buzzwords.\\n\\n\\n\\n\\nAI took this further. Tools like Mya (a chatbot launched in 2016) automated initial candidate screenings, asking questions and gauging responses. Meanwhile, platforms like Hired reversed the model, letting job seekers “bid” for employer attention. By 2020, AI could analyze tone in cover letters, predict cultural fit, and even simulate interviews. The promise? Efficiency and precision. The catch? Bias—algorithms often mirrored the prejudices of their training data, disproportionately excluding certain demographics.\\n\\n\\n\\nThe Modern Landscape: Personalization and Immersion\\n\\n\\n\\n\\nToday, in 2025, job search technology is hyper-personalized and immersive. Virtual reality (VR) job fairs let candidates “walk” through offices and “meet” teams from home. AI assistants, like the fictional “JobQuest Pro,” guide users through tailored career paths, suggesting roles based on real-time labor market data and personal interests. Blockchain verifies credentials instantly, eliminating resume fraud, while gamified assessments test skills in real-world scenarios.\\n\\n\\n\\n\\nTake “CareerFinderX,” a hypothetical platform born from this era. It combines AI-driven matching, VR previews, and a social feed of micro-mentorships—bite-sized advice from industry pros. Users input preferences (e.g., remote work, creative freedom), and the system generates a “Job Fit Score” alongside 3D tours of potential workplaces. It’s a far cry from the newspaper ads of old, reflecting a world where technology doesn’t just find jobs—it shapes careers.\\n\\n\\n\\nChallenges and Ethical Considerations\\n\\n\\n\\n\\nThis evolution isn’t without pitfalls. Data privacy looms large—platforms harvest vast amounts of personal information, raising questions about consent and security. AI’s opaque decision-making can frustrate users, especially when rejections lack explanation. And the digital divide persists; those without high-speed internet or tech literacy are left behind. Balancing innovation with equity remains a pressing challenge.\\n\\n\\n\\nLooking Ahead: The Future of Job Discovery\\n\\n\\n\\n\\nWhat’s next? Experts predict quantum computing could analyze global job markets in seconds, while brain-computer interfaces might one day let us “think” our applications into existence. The line between human intuition and machine assistance will blur, creating a symbiosis where technology amplifies ambition. Yet, the core of job searching—finding purpose—will endure, no matter the tools.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=40)\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "xkKr__KEQauj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the Cunks\n",
        "# from docx import Document\n",
        "\n",
        "# doc = Document()\n",
        "\n",
        "# for i, chunk in enumerate(texts, 1):\n",
        "#     doc.add_paragraph(f\"Chunk {i}:\")\n",
        "#     doc.add_paragraph(chunk.page_content)\n",
        "#     doc.add_paragraph(\"\")\n",
        "\n",
        "# doc.save(\"Split_Evolution_of_Job_Search_Technology.docx\")"
      ],
      "metadata": {
        "id": "w9b1ImEFReSe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "map_prompt_template = \"\"\"\n",
        "Shorten the following text while keeping its original wording and main ideas intact. Remove extra details but don’t rephrase completely:\n",
        "{text}\n",
        "\"\"\"\n",
        "reduce_prompt_template = \"\"\"\n",
        "Combine these shortened texts into a concise summary, keeping the original phrasing where possible:\n",
        "{text}\n",
        "\"\"\"\n",
        "map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
        "reduce_prompt = PromptTemplate(template=reduce_prompt_template, input_variables=[\"text\"])\n",
        "chain = load_summarize_chain(\n",
        "    llm,\n",
        "    chain_type=\"map_reduce\",\n",
        "    map_prompt=map_prompt,\n",
        "    combine_prompt=reduce_prompt\n",
        ")\n",
        "response = chain.invoke({\"input_documents\": texts})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7WoyzjvrRfKo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X5mfTRxeTmaG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "summary = response[\"output_text\"]\n",
        "\n",
        "doc = Document()\n",
        "doc.add_heading(\"Summary of The Evolution of Job Search Technology\", level=1)\n",
        "doc.add_paragraph(summary)\n",
        "\n",
        "# Save the document\n",
        "output_file = \"Summary_Evolution_of_Job_Search_Technology.docx\"\n",
        "doc.save(output_file)"
      ],
      "metadata": {
        "id": "xeJERqHTTXGQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "ZHGJK4W5TY9d",
        "outputId": "6e7d6ce4-7730-42f7-b0e4-1e3628f24d5c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The article explores the evolution of job search technology from traditional methods to advanced digital platforms. It details the transition from print media and community noticeboards to online job boards and social media, emphasizing the role of technology in reshaping recruitment practices. The rise of artificial intelligence and algorithms in the hiring process is highlighted, showcasing how these innovations offer efficiency but also raise ethical concerns. The future of job discovery is envisioned with hyper-personalized experiences, virtual reality interactions, and AI-driven career guidance, while also addressing challenges like data privacy and the digital divide. Ultimately, the quest for meaningful work remains a constant amidst technological advancements.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fFbP6oj2UubV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}